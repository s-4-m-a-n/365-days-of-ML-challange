{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459ce66e",
   "metadata": {},
   "source": [
    "# Multilabel Classification using Tensorflow Core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52743b59",
   "metadata": {},
   "source": [
    "### Dataset : Question from cross Validation stack exchange\n",
    "\n",
    "API : \n",
    "```\n",
    "kaggle datasets download -d stackoverflow/statsquestions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029ee4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install kaggle -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52f50266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c347446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'architecture implementations'\t LICENSE\r\n",
      " daily_logs.md\t\t\t README.md\r\n",
      " kaggle.json\t\t\t'tensorflow from basic to advance'\r\n",
      "'keras basic to advance'\r\n"
     ]
    }
   ],
   "source": [
    "! cd ../../ && ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a915cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe54c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 ../../kaggle.json'\n",
      "Downloading statsquestions.zip to /home/suman/Desktop/365 days of ML challange/architecture implementations/Logistic Regression\n",
      "100%|████████████████████████████████████████| 158M/158M [00:26<00:00, 6.64MB/s]\n",
      "100%|████████████████████████████████████████| 158M/158M [00:26<00:00, 6.19MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d stackoverflow/statsquestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c480682",
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod 600 ../../kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7bf912c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Binary Logistic Regression with Tensorflow core.ipynb'\r\n",
      "'Multiclass Logistic Regression with tensorfow core.ipynb'\r\n",
      "'Multilabel Classification.ipynb'\r\n",
      " statsquestions.zip\r\n",
      "'Vanishing Gradient problem.ipynb'\r\n",
      "'with Tensorflow core.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf3bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "zip_file_path = \"statsquestions.zip\"\n",
    "destination_directory = \"dataset\"\n",
    "\n",
    "shutil.unpack_archive(zip_file_path, destination_directory, 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fe4107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Binary Logistic Regression with Tensorflow core.ipynb'\r\n",
      " dataset\r\n",
      "'Multiclass Logistic Regression with tensorfow core.ipynb'\r\n",
      "'Multilabel Classification.ipynb'\r\n",
      " statsquestions.zip\r\n",
      "'Vanishing Gradient problem.ipynb'\r\n",
      "'with Tensorflow core.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b43396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database.sqlite', 'Answers.csv', 'Tags.csv', 'Questions.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb00d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65eff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv(\"dataset/Questions.csv\", encoding='iso-8859-1')\n",
    "df_tags = pd.read_csv(\"dataset/Tags.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d360bc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85085, 6), (244228, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.shape, df_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9094510c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2010-07-19T19:25:39Z</td>\n",
       "      <td>208</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010-07-19T19:28:44Z</td>\n",
       "      <td>138</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-07-19T19:31:47Z</td>\n",
       "      <td>58</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
       "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
       "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learn...   \n",
       "1                     Forecasting demographic census   \n",
       "2  Bayesian and frequentist reasoning in plain En...   \n",
       "3  What is the meaning of p values and t values i...   \n",
       "4  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  \n",
       "2  <p>How would you describe in plain English the...  \n",
       "3  <p>After taking a statistics course and then t...  \n",
       "4  <p>There is an old saying: \"Correlation does n...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfae2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>elicitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>normality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1          prior\n",
       "2   1    elicitation\n",
       "3   2  distributions\n",
       "4   2      normality"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d8363b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "r                     13236\n",
       "regression            10959\n",
       "machine-learning       6089\n",
       "time-series            5559\n",
       "probability            4217\n",
       "hypothesis-testing     3869\n",
       "self-study             3732\n",
       "distributions          3501\n",
       "logistic               3316\n",
       "classification         2881\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.Tag.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ebee5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "pls                       109\n",
       "geometric-distribution     47\n",
       "abbreviation                4\n",
       "pivot-table                 7\n",
       "software                  151\n",
       "cubic                       2\n",
       "sql                        23\n",
       "c#                         20\n",
       "euclidean                  60\n",
       "mcmc                      635\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.Tag.value_counts().sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee807d",
   "metadata": {},
   "source": [
    "# Taking only the top 100 frequent tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e2e3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd3cd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tags = df_tags.groupby(\"Tag\").size().reset_index(name='count')\n",
    "most_common_tags = grouped_tags.nlargest(NUM_CLASS, columns=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e6a55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>r</td>\n",
       "      <td>13236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>regression</td>\n",
       "      <td>10959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>machine-learning</td>\n",
       "      <td>6089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>time-series</td>\n",
       "      <td>5559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>probability</td>\n",
       "      <td>4217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>nonlinear-regression</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>cox-model</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>monte-carlo</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>proportion</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Tag  count\n",
       "986                      r  13236\n",
       "1020            regression  10959\n",
       "669       machine-learning   6089\n",
       "1220           time-series   5559\n",
       "946            probability   4217\n",
       "...                    ...    ...\n",
       "818   nonlinear-regression    514\n",
       "240              cox-model    510\n",
       "757            monte-carlo    504\n",
       "959             proportion    503\n",
       "21              algorithms    500\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d63d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOST_COMMON_TAGS = list(set(most_common_tags.Tag.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06307783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MOST_COMMON_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa58286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python, standard-deviation, goodness-of-fit, regression-coefficients, optimization, normal-distribution, conditional-probability, variance, correlation, interaction, ordinal, terminology, standard-error, probability, neural-networks, references, bayesian, categorical-data, anova, regression, prediction, expected-value, outliers, econometrics, bootstrap, spss, p-value, nonlinear-regression, random-variable, model-selection, covariance, dataset, deep-learning, data-visualization, algorithms, statistical-significance, survey, stochastic-processes, multiple-comparisons, classification, stata, clustering, feature-selection, distributions, t-test, self-study, multilevel-analysis, random-effects-model, cart, svm, chi-squared, logistic, arima, experiment-design, linear-model, proportion, maximum-likelihood, hypothesis-testing, autocorrelation, multivariate-analysis, mcmc, monte-carlo, sample-size, estimation, model, poisson, confidence-interval, data-transformation, repeated-measures, modeling, data-mining, cox-model, mathematical-statistics, matlab, predictive-models, forecasting, binary-data, generalized-linear-model, pca, simulation, inference, time-series, mixed-model, binomial, pdf, least-squares, missing-data, cross-validation, sampling, panel-data, factor-analysis, machine-learning, nonparametric, interpretation, residuals, r, random-forest, mean, multiple-regression, survival'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(MOST_COMMON_TAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a696752d",
   "metadata": {},
   "source": [
    "Now, let's remove tags which are not common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905c0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.Tag = df_tags.Tag.apply(lambda tag: tag if tag in MOST_COMMON_TAGS else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b135111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id            Tag\n",
       "0   1       bayesian\n",
       "1   1           None\n",
       "2   1           None\n",
       "3   2  distributions\n",
       "4   2           None"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eea32d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a325412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>bayesian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>distributions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>statistical-significance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                       Tag\n",
       "0   1                  bayesian\n",
       "3   2             distributions\n",
       "7   4             distributions\n",
       "8   4  statistical-significance\n",
       "9   6          machine-learning"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f076e0",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f0e643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-07-19T19:14:44Z</td>\n",
       "      <td>272</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2010-07-19T19:24:36Z</td>\n",
       "      <td>4</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2010-07-19T19:25:39Z</td>\n",
       "      <td>208</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010-07-19T19:28:44Z</td>\n",
       "      <td>138</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2010-07-19T19:31:47Z</td>\n",
       "      <td>58</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate  Score  \\\n",
       "0   6          5.0  2010-07-19T19:14:44Z    272   \n",
       "1  21         59.0  2010-07-19T19:24:36Z      4   \n",
       "2  22         66.0  2010-07-19T19:25:39Z    208   \n",
       "3  31         13.0  2010-07-19T19:28:44Z    138   \n",
       "4  36          8.0  2010-07-19T19:31:47Z     58   \n",
       "\n",
       "                                               Title  \\\n",
       "0  The Two Cultures: statistics vs. machine learn...   \n",
       "1                     Forecasting demographic census   \n",
       "2  Bayesian and frequentist reasoning in plain En...   \n",
       "3  What is the meaning of p values and t values i...   \n",
       "4  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  \n",
       "2  <p>How would you describe in plain English the...  \n",
       "3  <p>After taking a statistics course and then t...  \n",
       "4  <p>There is an old saying: \"Correlation does n...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "077eec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>&lt;p&gt;Last year, I read a blog post from &lt;a href=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>&lt;p&gt;What are some of the ways to forecast demog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>&lt;p&gt;How would you describe in plain English the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>&lt;p&gt;After taking a statistics course and then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>&lt;p&gt;There is an old saying: \"Correlation does n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   6  The Two Cultures: statistics vs. machine learn...   \n",
       "1  21                     Forecasting demographic census   \n",
       "2  22  Bayesian and frequentist reasoning in plain En...   \n",
       "3  31  What is the meaning of p values and t values i...   \n",
       "4  36  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>Last year, I read a blog post from <a href=...  \n",
       "1  <p>What are some of the ways to forecast demog...  \n",
       "2  <p>How would you describe in plain English the...  \n",
       "3  <p>After taking a statistics course and then t...  \n",
       "4  <p>There is an old saying: \"Correlation does n...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = df_questions[['Id', 'Title', 'Body']]\n",
    "df_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f783f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>Last year, I read a blog post from <a href=\"http://anyall.org/\">Brendan O\\'Connor</a> entitled <a href=\"http://anyall.org/blog/2008/12/statistics-vs-machine-learning-fight/\">\"Statistics vs. Machine Learning, fight!\"</a> that discussed some of the differences between the two fields.  <a href=\"http://andrewgelman.com/2008/12/machine_learnin/\">Andrew Gelman responded favorably to this</a>:</p>\\n\\n<p>Simon Blomberg: </p>\\n\\n<blockquote>\\n  <p>From R\\'s fortunes\\n  package: To paraphrase provocatively,\\n  \\'machine learning is statistics minus\\n  any checking of models and\\n  assumptions\\'.\\n  -- Brian D. Ripley (about the difference between machine learning\\n  and statistics) useR! 2004, Vienna\\n  (May 2004) :-) Season\\'s Greetings!</p>\\n</blockquote>\\n\\n<p>Andrew Gelman:</p>\\n\\n<blockquote>\\n  <p>In that case, maybe we should get rid\\n  of checking of models and assumptions\\n  more often. Then maybe we\\'d be able to\\n  solve some of the problems that the\\n  machine learning people can solve but\\n  we can\\'t!</p>\\n</blockquote>\\n\\n<p>There was also the <a href=\"http://projecteuclid.org/euclid.ss/1009213726\"><strong>\"Statistical Modeling: The Two Cultures\"</strong> paper</a> by Leo Breiman in 2001 which argued that statisticians rely too heavily on data modeling, and that machine learning techniques are making progress by instead relying on the <em>predictive accuracy</em> of models.</p>\\n\\n<p>Has the statistics field changed over the last decade in response to these critiques?  Do the <em>two cultures</em> still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines?</p>\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.iloc[0].Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91bab6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Two Cultures: statistics vs. machine learning?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.iloc[0].Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f664e372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'click me'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "HTML_TAG_PATTERN = \"<.*?>\"\n",
    "\n",
    "test_text = \"<HTML><a href='example.com'>click me</a></HTML>\"\n",
    "re.sub(HTML_TAG_PATTERN, \"\", test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2dec34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    HTML_TAG_PATTERN = \"<.*?>\"\n",
    "    clean_text = re.sub(HTML_TAG_PATTERN, \"\", text).lower()\n",
    "    return \" \".join(re.sub(r\"[^a-zA-Z0-9 ']\", ' ', clean_text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eafdb0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"last year i read a blog post from brendan o'connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r's fortunes package to paraphrase provocatively 'machine learning is statistics minus any checking of models and assumptions' brian d ripley about the difference between machine learning and statistics user 2004 vienna may 2004 season's greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we'd be able to solve some of the problems that the machine learning people can solve but we can't there was also the statistical modeling the two cultures paper by leo breiman in 2001 which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.iloc[:10].Body.apply(clean_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9521145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions[\"Body\"] = df_questions.Body.apply(clean_text)\n",
    "df_questions[\"Text\"] = df_questions.Title.apply(clean_text)+ ' ' + df_questions[\"Body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5d9f997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the two cultures statistics vs machine learning last year i read a blog post from brendan o'connor entitled statistics vs machine learning fight that discussed some of the differences between the two fields andrew gelman responded favorably to this simon blomberg from r's fortunes package to paraphrase provocatively 'machine learning is statistics minus any checking of models and assumptions' brian d ripley about the difference between machine learning and statistics user 2004 vienna may 2004 season's greetings andrew gelman in that case maybe we should get rid of checking of models and assumptions more often then maybe we'd be able to solve some of the problems that the machine learning people can solve but we can't there was also the statistical modeling the two cultures paper by leo breiman in 2001 which argued that statisticians rely too heavily on data modeling and that machine learning techniques are making progress by instead relying on the predictive accuracy of models has the statistics field changed over the last decade in response to these critiques do the two cultures still exist or has statistics grown to embrace machine learning techniques such as neural networks and support vector machines\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.Text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b0dff",
   "metadata": {},
   "source": [
    "## Merge Two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8ee62ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['distributions'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags[df_tags[\"Id\"] == 2].Tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fbdf033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags[df_tags[\"Id\"] == -2].Tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4efa551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tags_by_id(q_id):\n",
    "    return df_tags[df_tags[\"Id\"] == q_id].Tag.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5efa1023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ordinal'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_tags_by_id(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d054c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tags_row(row):\n",
    "    row[\"Tags\"] = extract_tags_by_id(row[\"Id\"])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de240555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                                                      21\n",
       "Title                       Forecasting demographic census\n",
       "Body     what are some of the ways to forecast demograp...\n",
       "Text     forecasting demographic census what are some o...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a1f0c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13629/190608515.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row[\"Tags\"] = extract_tags_by_id(row[\"Id\"])\n",
      "/tmp/ipykernel_13629/190608515.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  row[\"Tags\"] = extract_tags_by_id(row[\"Id\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Id                                                      21\n",
       "Title                       Forecasting demographic census\n",
       "Body     what are some of the ways to forecast demograp...\n",
       "Text     forecasting demographic census what are some o...\n",
       "Tags                                         [forecasting]\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_tags_row(df_questions.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd2238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = df_questions.apply(add_tags_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "004d2507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>[machine-learning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>[forecasting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>[bayesian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>[hypothesis-testing, t-test, p-value, interpre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>[correlation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   6  The Two Cultures: statistics vs. machine learn...   \n",
       "1  21                     Forecasting demographic census   \n",
       "2  22  Bayesian and frequentist reasoning in plain En...   \n",
       "3  31  What is the meaning of p values and t values i...   \n",
       "4  36  Examples for teaching: Correlation does not me...   \n",
       "\n",
       "                                                Tags  \n",
       "0                                 [machine-learning]  \n",
       "1                                      [forecasting]  \n",
       "2                                         [bayesian]  \n",
       "3  [hypothesis-testing, t-test, p-value, interpre...  \n",
       "4                                      [correlation]  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions.head()[[\"Id\", \"Title\", \"Tags\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bbadcf",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35436d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70d3c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c12eae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_binarizer = MultiLabelBinarizer()\n",
    "multi_label_binarizer.fit(df_questions.Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06880a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['algorithms', 'anova', 'arima', 'autocorrelation', 'bayesian',\n",
       "       'binary-data', 'binomial', 'bootstrap', 'cart', 'categorical-data',\n",
       "       'chi-squared', 'classification', 'clustering',\n",
       "       'conditional-probability', 'confidence-interval', 'correlation',\n",
       "       'covariance', 'cox-model', 'cross-validation', 'data-mining',\n",
       "       'data-transformation', 'data-visualization', 'dataset',\n",
       "       'deep-learning', 'distributions', 'econometrics', 'estimation',\n",
       "       'expected-value', 'experiment-design', 'factor-analysis',\n",
       "       'feature-selection', 'forecasting', 'generalized-linear-model',\n",
       "       'goodness-of-fit', 'hypothesis-testing', 'inference',\n",
       "       'interaction', 'interpretation', 'least-squares', 'linear-model',\n",
       "       'logistic', 'machine-learning', 'mathematical-statistics',\n",
       "       'matlab', 'maximum-likelihood', 'mcmc', 'mean', 'missing-data',\n",
       "       'mixed-model', 'model', 'model-selection', 'modeling',\n",
       "       'monte-carlo', 'multilevel-analysis', 'multiple-comparisons',\n",
       "       'multiple-regression', 'multivariate-analysis', 'neural-networks',\n",
       "       'nonlinear-regression', 'nonparametric', 'normal-distribution',\n",
       "       'optimization', 'ordinal', 'outliers', 'p-value', 'panel-data',\n",
       "       'pca', 'pdf', 'poisson', 'prediction', 'predictive-models',\n",
       "       'probability', 'proportion', 'python', 'r', 'random-effects-model',\n",
       "       'random-forest', 'random-variable', 'references', 'regression',\n",
       "       'regression-coefficients', 'repeated-measures', 'residuals',\n",
       "       'sample-size', 'sampling', 'self-study', 'simulation', 'spss',\n",
       "       'standard-deviation', 'standard-error', 'stata',\n",
       "       'statistical-significance', 'stochastic-processes', 'survey',\n",
       "       'survival', 'svm', 't-test', 'terminology', 'time-series',\n",
       "       'variance'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS = multi_label_binarizer.classes_\n",
    "LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a075814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 180\n",
    "VOCAB_SIZE = 1000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, lower=True)\n",
    "tokenizer.fit_on_texts(df_questions.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15e25b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_feature_vector(corpus):\n",
    "    sequences = tokenizer.texts_to_sequences(corpus)\n",
    "    return pad_sequences(sequences, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "928668cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "         60, 262, 345, 543, 276, 637, 324,   2, 355,   3, 411,  37, 262,\n",
       "        345, 543, 276,  12,  63,   5,   1, 472,  76,   1,  60,   4,  15,\n",
       "         37, 277,   4, 276,   7, 262,  72,   5, 143,   9, 112,  94,   1,\n",
       "        173,  76, 543, 276,   9, 262, 684, 279,  10,  12, 151, 634,  55,\n",
       "         84, 109,   5,   5, 143,   9, 747,  96, 769,  82, 634,  21, 404,\n",
       "          4, 641,  63,   5,   1, 656,  12,   1, 543, 276, 348,  33, 641,\n",
       "         32,  55, 446,  45, 102, 111,   1, 243, 841,   1,  60, 447,  54,\n",
       "         10,  48,  12, 456,  22,  16, 841,   9,  12, 543, 276, 949,  19,\n",
       "        978,  54, 455,  22,   1, 892, 454,   5, 143, 104,   1, 262, 199,\n",
       "          1, 637,  10, 260,   4,  99,  49,   1,  60, 352,  34, 104, 262,\n",
       "          4, 543, 276, 949, 172,  23, 550, 974,   9, 938, 290]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_feature_vector([df_questions.Text.values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8541e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_to_label(preds):\n",
    "    label_prob = [(LABELS[i], prob[0]) for i, prob in enumerate(preds.numpy().tolist())]\n",
    "    return dict(sorted(label_prob, key=lambda kv:kv[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "439c85d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[0.28406227],\n",
       "       [0.36518085],\n",
       "       [0.9222305 ],\n",
       "       [0.56961286],\n",
       "       [0.764382  ],\n",
       "       [0.02735341],\n",
       "       [0.5669421 ],\n",
       "       [0.64930797],\n",
       "       [0.0144248 ],\n",
       "       [0.6560919 ]], dtype=float32)>"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_preds = tf.random.uniform([10, 1])\n",
    "dummy_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b6820313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arima': 0.9222304821014404,\n",
       " 'bayesian': 0.764382004737854,\n",
       " 'categorical-data': 0.6560919284820557,\n",
       " 'bootstrap': 0.6493079662322998,\n",
       " 'autocorrelation': 0.5696128606796265,\n",
       " 'binomial': 0.5669420957565308,\n",
       " 'anova': 0.3651808500289917,\n",
       " 'algorithms': 0.2840622663497925,\n",
       " 'binary-data': 0.027353405952453613,\n",
       " 'cart': 0.014424800872802734}"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_to_label(dummy_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4198721e",
   "metadata": {},
   "source": [
    "## Prepare the Input  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a9cf234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = text_to_feature_vector(df_questions.Text)\n",
    "y_train = multi_label_binarizer.transform(df_questions.Tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6b052366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([149,   2,  95,   4, 156,   3,   5,  51,   7, 325, 628, 130,   2,\n",
       "       215, 130,   2, 108,   8,   9,  78,  11,  51, 678,   2,  48,  20,\n",
       "         7,   1,   7, 386,   4,  21, 351, 450, 330,   2,  41,  69,   4,\n",
       "         1, 713,  66, 405,  10, 256,  70,   9,  10,   1, 149,   1, 256,\n",
       "        70,   7, 270, 140, 175,   1,  71,  75,  11,  51,   9,  82, 175,\n",
       "         1,  71,   5, 210,   1, 149,   7,  96,  45,  19,  60,   1, 149,\n",
       "         5, 713,   9,   1, 149,   5,  75,  10, 237,   4,  18,  44, 428,\n",
       "        22,   1, 244,  55,  18,  10,  72, 393, 713,  55, 150,   4, 635,\n",
       "        11, 185,   1,   2, 446, 222,   5,   3, 218, 154,  20,   7,  12,\n",
       "        74,   1, 497,  10,   3, 393,   9, 633,   1,   5,  15, 840,   3,\n",
       "       218, 428,  72, 484,  93, 212,  25,  15,  25, 226,   4,  21,   1,\n",
       "       127, 503,  11,  24, 151,  11,   1, 642,  12,  20,   7,  10, 947,\n",
       "        11,   1, 429,  85,  51, 147,  10,  24, 151,   7, 130,   2,   7,\n",
       "       594,  11,  74,   1,  48,   7,  29, 203,  10,  24, 151], dtype=int32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d1894b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "566c5a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85085, 180), (85085, 100))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0feed93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 180), (10000, 100))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sample = x_train[:10_000]\n",
    "y_train_sample = y_train[:10_000]\n",
    "\n",
    "x_train_sample.shape, y_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a2a1446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.cast(tf.transpose(x_train_sample), \"float32\")/VOCAB_SIZE\n",
    "y = tf.constant(tf.transpose(y_train_sample))/VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f7855cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([180, 10000]), TensorShape([100, 10000]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28821eed",
   "metadata": {},
   "source": [
    "# Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aea7a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    exp_z = tf.math.exp(-z)\n",
    "    return 1 / (1 + exp_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274777ed",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "01a39f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y_true, y_pred, from_logits=False):\n",
    "    y_true = tf.cast(tf.constant(y_true), \"float32\")\n",
    "    y_pred = tf.cast(tf.constant(y_pred), \"float32\")\n",
    "    if from_logits:\n",
    "        y_pred = sigmoid(y_pred)\n",
    "    epsilon = 1e-7  # A small value to prevent log(1) condition\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = y_true * tf.math.log(y_pred) + (1 - y_true)*tf.math.log(1-y_pred)\n",
    "    return -tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0a17de36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.17625475, 0.9428749 , 0.9179132 , 0.34259653, 0.09808779,\n",
       "       0.56494594, 0.575238  , 0.76359785, 0.49316752, 0.39830625],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_preds = tf.random.uniform([10])\n",
    "dummy_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "a0649768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 0., 0., 1., 0., 0., 1., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y_true = tf.math.round(tf.random.uniform([10]))\n",
    "dummy_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9a14c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9079709>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy(dummy_y_true, dummy_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "377775e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_y_true = tf.math.round(dummy_preds)\n",
    "dummy_y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "09b2e9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.34423557>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy(dummy_y_true, dummy_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "52a055a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.192093e-07>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_cross_entropy(dummy_y_true, dummy_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4870f34",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "416f36d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelLogisticRegression(tf.Module):\n",
    "    def __init__(self, n_classes, name=None, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.is_built = False\n",
    "        self.n_class = n_classes\n",
    "    \n",
    "    def build(self, num_features):\n",
    "        # randomly generate bias and weights\n",
    "        self.weights = tf.Variable(tf.random.normal([self.n_class, num_features]), name=\"weights\")\n",
    "        self.bias = tf.Variable(tf.zeros([self.n_class, 1]), name=\"bias\")\n",
    "        print(\"build successfully\")\n",
    "        \n",
    "    def predict(self, x):\n",
    "        #compute model output\n",
    "        # compute logits\n",
    "        logits = self.weights @ x + self.bias\n",
    "        return sigmoid(logits)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            self.build(x.shape[0])\n",
    "            self.is_built = True\n",
    "        return self.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "07208f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorShape([100, 10]),\n",
       " <tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       " array([5.41225433e-01, 8.06589782e-01, 8.24252546e-01, 4.90969121e-01,\n",
       "        5.42748952e-03, 8.99103165e-01, 4.07781959e-01, 9.93144512e-01,\n",
       "        2.53488198e-02, 8.43413651e-01, 5.29198647e-01, 5.62053740e-01,\n",
       "        9.02662992e-01, 9.80902076e-01, 3.90235335e-01, 9.80073392e-01,\n",
       "        2.35534966e-01, 9.03265119e-01, 5.06120205e-01, 5.77651244e-03,\n",
       "        9.39405799e-01, 9.23120603e-02, 6.38845995e-06, 9.45330322e-01,\n",
       "        1.67244478e-04, 2.72230804e-01, 9.99994516e-01, 1.75339375e-02,\n",
       "        3.85065615e-01, 6.94571793e-01, 4.77428406e-01, 1.25839144e-01,\n",
       "        1.21650375e-01, 5.95242195e-02, 9.98339891e-01, 1.88916340e-01,\n",
       "        8.93396318e-01, 1.43894345e-01, 5.09555265e-03, 9.53627586e-01,\n",
       "        2.47141004e-01, 9.46795285e-01, 4.38318551e-02, 9.98462319e-01,\n",
       "        7.21878529e-01, 5.20805836e-01, 5.42146444e-01, 9.89803791e-01,\n",
       "        4.13427383e-01, 9.99831200e-01, 7.49128819e-01, 1.23403632e-04,\n",
       "        4.61123846e-02, 9.96362746e-01, 7.48517931e-01, 9.40181553e-01,\n",
       "        7.96229541e-01, 7.84476399e-01, 9.03586507e-01, 9.89250660e-01,\n",
       "        5.30177960e-03, 1.93606451e-01, 1.39420554e-01, 5.97026907e-02,\n",
       "        3.59627418e-02, 3.24823946e-01, 9.92182642e-03, 9.99262393e-01,\n",
       "        9.63321209e-01, 9.71239235e-04, 9.66816902e-01, 2.95785852e-02,\n",
       "        9.99325633e-01, 7.79355288e-01, 2.49819979e-01, 1.85798854e-04,\n",
       "        9.55405593e-01, 4.53938544e-01, 1.31951168e-01, 3.61765027e-02,\n",
       "        6.28778264e-02, 1.14108492e-02, 9.36142564e-01, 1.35721177e-01,\n",
       "        5.13643086e-01, 8.87420833e-01, 5.59581816e-02, 9.97460723e-01,\n",
       "        2.98803419e-01, 9.11037982e-01, 1.01911072e-02, 3.72666046e-02,\n",
       "        7.10994661e-01, 1.86122581e-02, 8.54167998e-01, 9.94958460e-01,\n",
       "        2.00171228e-02, 1.70836097e-03, 9.56269681e-01, 9.88406062e-01],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLabelLogisticRegression(len(LABELS))\n",
    "output = model(x[:, :10])\n",
    "output.shape, output[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1f53c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 180])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb2daca",
   "metadata": {},
   "source": [
    "# Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2d83cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred, threshold=0.5):\n",
    "    y_pred = tf.cast(y_pred >= 0.5, \"int16\")\n",
    "    y_true = tf.cast(y_true, \"int16\")\n",
    "    match = tf.cast(tf.equal(y_true, y_pred), \"float32\")\n",
    "    return tf.reduce_mean(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f55e9c",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "14c54930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining training function\n",
    "def train(model, x_train, y_train, learning_rate=0.01):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x_train)\n",
    "        acc = calculate_accuracy(y_train, y_pred)\n",
    "        loss = binary_cross_entropy(y_train, y_pred)\n",
    "\n",
    "    dw, db = tape.gradient(loss, [model.weights, model.bias])\n",
    "    model.weights.assign_sub(learning_rate * dw)\n",
    "    model.bias.assign_sub(learning_rate * db)\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f07473a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.3514203>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.502557>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model, x, y, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffa86c",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "38c9bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_training_summary(loss, accuracy, epoch):\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"EPOCH: {epoch} --- loss: {loss}---accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4fce1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model initiate\n",
    "model = MultiLabelLogisticRegression(len(LABELS))\n",
    "LOSS_HISTORY = []\n",
    "ACC_HISTORY = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "4d13d3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10 --- loss: 0.2084408700466156---accuracy: 0.921949028968811\n",
      "EPOCH: 20 --- loss: 0.20296968519687653---accuracy: 0.9244179725646973\n",
      "EPOCH: 30 --- loss: 0.19774170219898224---accuracy: 0.9268820285797119\n",
      "EPOCH: 40 --- loss: 0.1927422434091568---accuracy: 0.9291769862174988\n",
      "EPOCH: 50 --- loss: 0.187957763671875---accuracy: 0.9313349723815918\n",
      "EPOCH: 60 --- loss: 0.18337567150592804---accuracy: 0.9334579706192017\n",
      "EPOCH: 70 --- loss: 0.17898434400558472---accuracy: 0.9354559779167175\n",
      "EPOCH: 80 --- loss: 0.1747729331254959---accuracy: 0.9374570250511169\n",
      "EPOCH: 90 --- loss: 0.170731320977211---accuracy: 0.9393569827079773\n",
      "EPOCH: 100 --- loss: 0.1668502539396286---accuracy: 0.9411569833755493\n",
      "EPOCH: 110 --- loss: 0.16312091052532196---accuracy: 0.942874014377594\n",
      "EPOCH: 120 --- loss: 0.15953519940376282---accuracy: 0.9444860219955444\n",
      "EPOCH: 130 --- loss: 0.1560855358839035---accuracy: 0.9460189938545227\n",
      "EPOCH: 140 --- loss: 0.15276479721069336---accuracy: 0.9475749731063843\n",
      "EPOCH: 150 --- loss: 0.1495663821697235---accuracy: 0.9490209817886353\n",
      "EPOCH: 160 --- loss: 0.14648404717445374---accuracy: 0.9503949880599976\n",
      "EPOCH: 170 --- loss: 0.1435120403766632---accuracy: 0.9517599940299988\n",
      "EPOCH: 180 --- loss: 0.1406448781490326---accuracy: 0.9530919790267944\n",
      "EPOCH: 190 --- loss: 0.1378774344921112---accuracy: 0.9543250203132629\n",
      "EPOCH: 200 --- loss: 0.1352049708366394---accuracy: 0.9554749727249146\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 200\n",
    "LEARNING_RATE = 1\n",
    "\n",
    "#  Training Loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loss, acc = train(model, x, y, LEARNING_RATE)\n",
    "    LOSS_HISTORY.append(loss)\n",
    "    ACC_HISTORY.append(acc)\n",
    "    display_training_summary(loss, acc, epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce8b45",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0a959f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_questions.iloc[1].Text\n",
    "y_true_label = df_questions.iloc[1].Tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "d5bd77db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"forecasting demographic census what are some of the ways to forecast demographic census with some validation and calibration techniques some of the concerns census blocks vary in sizes as rural areas are a lot larger than condensed urban areas is there a need to account for the area size difference if let's say i have census data dating back to 4 5 census periods how far can i forecast it into the future if some of the census zone change lightly in boundaries how can i account for that change what are the methods to validate census forecasts for example if i have data for existing 5 census periods should i model the first 3 and test it on the latter two or is there another way what's the state of practice in forecasting census data and what are some of the state of the art methods\""
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "06a5dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['forecasting'], dtype=object)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b26a6a6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multi_label_binarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_true_label \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_label_binarizer\u001b[49m\u001b[38;5;241m.\u001b[39mtransform([y_true_label])\n\u001b[1;32m      2\u001b[0m y_true_label\n",
      "\u001b[0;31mNameError\u001b[0m: name 'multi_label_binarizer' is not defined"
     ]
    }
   ],
   "source": [
    "y_true_label = multi_label_binarizer.transform([y_true_label])\n",
    "y_true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "058f7d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  38,  19,  63,   5,   1, 846,   4, 569,  17,\n",
       "         63, 379,   9, 949,  63,   5,   1,  10, 821,  23,  19,   3, 568,\n",
       "        822, 119,   7,  45,   3, 150,   4, 635,  11,   1, 725, 155, 173,\n",
       "         27, 505, 161,   2,  18,  16, 900,   4,  47,  42,  31, 443,  33,\n",
       "          2, 569,  20, 164,   1,  27,  63,   5,   1, 315,  10,  31,  33,\n",
       "          2, 635,  11,  12, 315,  38,  19,   1, 297,   4,  11, 110,  27,\n",
       "          2,  18,  16,  11,  42,  84,   2,  25,   1, 140,  28,   9,  43,\n",
       "         20,  22,   1,  60,  34,   7,  45, 302, 101,   1, 448,   5,  10,\n",
       "         16,   9,  38,  19,  63,   5,   1, 448,   5,   1, 297]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_rep = text_to_feature_vector([text])\n",
    "vector_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "9c24e7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 180)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ef0e41da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([180, 1])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = tf.cast(tf.transpose(vector_rep), \"float32\")\n",
    "input_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "e063c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "cf874072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.round(tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a3ff3c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.7842>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(y_true_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f0687222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chi-squared': 1.0,\n",
       " 'clustering': 1.0,\n",
       " 'confidence-interval': 1.0,\n",
       " 'covariance': 1.0,\n",
       " 'distributions': 1.0,\n",
       " 'generalized-linear-model': 1.0,\n",
       " 'goodness-of-fit': 1.0,\n",
       " 'inference': 1.0,\n",
       " 'least-squares': 1.0,\n",
       " 'machine-learning': 1.0,\n",
       " 'mathematical-statistics': 1.0,\n",
       " 'monte-carlo': 1.0,\n",
       " 'normal-distribution': 1.0,\n",
       " 'p-value': 1.0,\n",
       " 'pca': 1.0,\n",
       " 'sample-size': 1.0,\n",
       " 'sampling': 1.0,\n",
       " 'simulation': 1.0,\n",
       " 'spss': 1.0,\n",
       " 'standard-deviation': 1.0,\n",
       " 'terminology': 1.0,\n",
       " 'algorithms': 0.0,\n",
       " 'anova': 0.0,\n",
       " 'arima': 0.0,\n",
       " 'autocorrelation': 0.0,\n",
       " 'bayesian': 0.0,\n",
       " 'binary-data': 0.0,\n",
       " 'binomial': 0.0,\n",
       " 'bootstrap': 0.0,\n",
       " 'cart': 0.0,\n",
       " 'categorical-data': 0.0,\n",
       " 'classification': 0.0,\n",
       " 'conditional-probability': 0.0,\n",
       " 'correlation': 0.0,\n",
       " 'cox-model': 0.0,\n",
       " 'cross-validation': 0.0,\n",
       " 'data-mining': 0.0,\n",
       " 'data-transformation': 0.0,\n",
       " 'data-visualization': 0.0,\n",
       " 'dataset': 0.0,\n",
       " 'deep-learning': 0.0,\n",
       " 'econometrics': 0.0,\n",
       " 'estimation': 0.0,\n",
       " 'expected-value': 0.0,\n",
       " 'experiment-design': 0.0,\n",
       " 'factor-analysis': 0.0,\n",
       " 'feature-selection': 0.0,\n",
       " 'forecasting': 0.0,\n",
       " 'hypothesis-testing': 0.0,\n",
       " 'interaction': 0.0,\n",
       " 'interpretation': 0.0,\n",
       " 'linear-model': 0.0,\n",
       " 'logistic': 0.0,\n",
       " 'matlab': 0.0,\n",
       " 'maximum-likelihood': 0.0,\n",
       " 'mcmc': 0.0,\n",
       " 'mean': 0.0,\n",
       " 'missing-data': 0.0,\n",
       " 'mixed-model': 0.0,\n",
       " 'model': 0.0,\n",
       " 'model-selection': 0.0,\n",
       " 'modeling': 0.0,\n",
       " 'multilevel-analysis': 0.0,\n",
       " 'multiple-comparisons': 0.0,\n",
       " 'multiple-regression': 0.0,\n",
       " 'multivariate-analysis': 0.0,\n",
       " 'neural-networks': 0.0,\n",
       " 'nonlinear-regression': 0.0,\n",
       " 'nonparametric': 0.0,\n",
       " 'optimization': 0.0,\n",
       " 'ordinal': 0.0,\n",
       " 'outliers': 0.0,\n",
       " 'panel-data': 0.0,\n",
       " 'pdf': 0.0,\n",
       " 'poisson': 0.0,\n",
       " 'prediction': 0.0,\n",
       " 'predictive-models': 0.0,\n",
       " 'probability': 0.0,\n",
       " 'proportion': 0.0,\n",
       " 'python': 0.0,\n",
       " 'r': 0.0,\n",
       " 'random-effects-model': 0.0,\n",
       " 'random-forest': 0.0,\n",
       " 'random-variable': 0.0,\n",
       " 'references': 0.0,\n",
       " 'regression': 0.0,\n",
       " 'regression-coefficients': 0.0,\n",
       " 'repeated-measures': 0.0,\n",
       " 'residuals': 0.0,\n",
       " 'self-study': 0.0,\n",
       " 'standard-error': 0.0,\n",
       " 'stata': 0.0,\n",
       " 'statistical-significance': 0.0,\n",
       " 'stochastic-processes': 0.0,\n",
       " 'survey': 0.0,\n",
       " 'survival': 0.0,\n",
       " 'svm': 0.0,\n",
       " 't-test': 0.0,\n",
       " 'time-series': 0.0,\n",
       " 'variance': 0.0}"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_to_label(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c86644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922ca38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480d3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
