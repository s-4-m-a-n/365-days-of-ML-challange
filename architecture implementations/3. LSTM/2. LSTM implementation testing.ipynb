{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9892e002-691a-418a-9ecf-14179a3b762d",
   "metadata": {},
   "source": [
    "# LSTM implementation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd3ea205-e748-4310-9a0f-d8d4a1e17a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cc96fd-7768-4488-a3c5-89833717b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTMcell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # weights for forget gate\n",
    "        self.W_f = nn.Parameter(torch.randn(self.input_size+self.hidden_size, self.hidden_size))\n",
    "        self.b_f = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "\n",
    "        # weigths for input gate\n",
    "        self.W_i = nn.Parameter(torch.randn(self.input_size+self.hidden_size, self.hidden_size))\n",
    "        self.b_i = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "\n",
    "        # weights for candidate gate\n",
    "        self.W_c = nn.Parameter(torch.randn(self.input_size+self.hidden_size, self.hidden_size))\n",
    "        self.b_c = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "\n",
    "        # weights for output gate\n",
    "        self.W_o = nn.Parameter(torch.randn(self.input_size+self.hidden_size, self.hidden_size))\n",
    "        self.b_o = nn.Parameter(torch.zeros(self.hidden_size))\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        # x -> (batch_size, embd_size)\n",
    "        # h_prev -> (batch_size, vector_size)\n",
    "        # c_prev -> (batch_size, vector_size)\n",
    "\n",
    "        x_h_prev = torch.cat((x, h_prev), dim=1)\n",
    "        # --- forget gate ------------------------\n",
    "        # compute ft\n",
    "        ft = torch.sigmoid(\n",
    "            x_h_prev @ self.W_f + self.b_f\n",
    "        )\n",
    "\n",
    "        c_state = c_prev * ft\n",
    "        # ------ input gate ----------------------\n",
    "        it = torch.sigmoid(\n",
    "            x_h_prev @ self.W_i + self.b_i\n",
    "        )\n",
    "    \n",
    "        ct_cap = torch.tanh(\n",
    "            x_h_prev @ self.W_c + self.b_c\n",
    "        )\n",
    "        c_state = c_state + it * ct_cap \n",
    "        #--------output_gate --------------------\n",
    "        ot = torch.sigmoid(\n",
    "            x_h_prev @ self.W_o + self.b_o\n",
    "        )\n",
    "        h_state = torch.tanh(c_state) * ot\n",
    "\n",
    "        return c_state, h_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac00e59-77de-4265-a508-b49d49ececc3",
   "metadata": {},
   "source": [
    "## Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787d7c9c-d83a-4696-bad6-8d1b3ea3b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm_cell = LSTMcell(self.input_size, self.hidden_size)\n",
    "        self.fcl = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # input_seq -> (batch_size, seq_length, input_size)\n",
    "        self.batch_size = input_seq.size(0)\n",
    "        self.seq_length = input_seq.size(1)\n",
    "\n",
    "        h_prev = torch.zeros((self.batch_size, self.hidden_size)).to(input_seq.device)\n",
    "        c_prev = torch.zeros((self.batch_size, self.hidden_size)).to(input_seq.device)\n",
    "\n",
    "        outputs = []\n",
    "        for t_step in range(self.seq_length):\n",
    "            x = input_seq[:, t_step, :]\n",
    "            h_prev, c_prev = self.lstm_cell(x, h_prev, c_prev)\n",
    "            y_pred = self.fcl(h_prev)            \n",
    "            outputs.append(y_pred.unsqueeze(1))\n",
    "\n",
    "        return torch.cat(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6410fcc-1bb5-4f26-8cef-1b85f0b75e80",
   "metadata": {},
   "source": [
    "## Dummy task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40189989-99c8-4b4b-849f-600cf79aee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_number_prediction(model_class):\n",
    "    # ------ hyper parameter --------------\n",
    "    seq_len = 5\n",
    "    batch_size = 16\n",
    "    input_size = 1\n",
    "    hidden_size = 32\n",
    "    epochs = 1000\n",
    "\n",
    "    # ------- data preparation ------------\n",
    "    # Pick random starting numbers for each batch (e.g. 0â€“99)\n",
    "    starts = torch.randint(0, 10, (2, 1, 1), dtype=torch.float)\n",
    "    # Create offset sequence [0, 1, 2, ..., seq_len-1]\n",
    "    offsets = torch.arange(5, dtype=torch.float).view(1, 5, 1)\n",
    "    # Add start + offsets to form sequences\n",
    "    x = starts + offsets\n",
    "    y = x + 1\n",
    "\n",
    "    # ------- model config -------------\n",
    "    model = model_class(input_size, hidden_size, input_size)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # ------- model training -------------\n",
    "    for epoch in range(epochs):\n",
    "        # forward pass\n",
    "        seq_out = model(x)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = loss_fn(seq_out, y)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch} - loss: {loss.item()}\")\n",
    "        \n",
    "        # back propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # model testing\n",
    "    print(\"====predictions =======\")\n",
    "    test_x = torch.tensor([[[1.], [2], [3], [4], [5]]])\n",
    "    y_pred = model(test_x)\n",
    "    for i, j in zip(test_x.flatten(), y_pred.flatten()):\n",
    "        print(f\" {round(i.item())} -> {round(j.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0656b98e-4e97-4f69-9b4e-2d65d6511227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - loss: 46.84516525268555\n",
      "epoch: 100 - loss: 0.03893999755382538\n",
      "epoch: 200 - loss: 1.5845322423047037e-06\n",
      "epoch: 300 - loss: 7.054268193890101e-12\n",
      "epoch: 400 - loss: 6.707523533995563e-13\n",
      "epoch: 500 - loss: 5.939568975543708e-11\n",
      "epoch: 600 - loss: 7.736520046819351e-07\n",
      "epoch: 700 - loss: 8.70841159600344e-12\n",
      "epoch: 800 - loss: 2.283400205027597e-11\n",
      "epoch: 900 - loss: 3.304146218852111e-07\n",
      "====predictions =======\n",
      " 1 -> 2\n",
      " 2 -> 3\n",
      " 3 -> 4\n",
      " 4 -> 5\n",
      " 5 -> 6\n"
     ]
    }
   ],
   "source": [
    "trained_model = next_number_prediction(SimpleLSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b009806-2ced-4efc-804f-e11e578716d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
