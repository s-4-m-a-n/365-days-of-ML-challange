{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abad6d75",
   "metadata": {},
   "source": [
    "# Custom Loss\n",
    "- In machine learning, a loss function, also known as a cost function or objective function, is a mathematical function that quantifies the difference between the predicted output of a model and the actual expected output. It represents the error or discrepancy between the model's predictions and the ground truth.\n",
    "- Note that, loss is associated with a single example whereas cost is associated with a training batch (average of loss of each example of a batch)\n",
    "- Ways to create custom loss functions in Keras\n",
    "   - using python function that takes y_true and y_pred values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b763f",
   "metadata": {},
   "source": [
    "## 1. Function based custom loss\n",
    "\n",
    "The first method involves creating a function that accepts inputs **y_true** and **y_pred**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e3d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 07:45:54.911014: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-17 07:45:54.955888: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-17 07:45:54.956803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-17 07:45:55.992903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdefd6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input((10)),\n",
    "    layers.Dense(10, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "363239ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 10]), TensorShape([10, 1]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([10, 10])\n",
    "y_true = tf.round(tf.random.uniform((10, 1), minval=0, maxval=1))\n",
    "x.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50195b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "830cbf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=custom_MSE, optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a98c2cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2496\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2481\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2466\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2451\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2436\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2422\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2409\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2395\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2381\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63caf3f250>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_true , epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed130c",
   "metadata": {},
   "source": [
    "Loss function is working fine, you can see the loss value is reducing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bb4eb4",
   "metadata": {},
   "source": [
    "## Subclassing based custom loss\n",
    "If you need a loss function that takes in parameters beside **y_true** and **y_pred**, you can subclass the **tf.keras.losses.Loss** class and implement the following two methods:\n",
    "- **\\_\\_init\\_\\_(self)**: accept parameters to pass during the call of your loss function\n",
    "- **call(self, y_true, y_pred)**: use the targets (y_true) and the model predictions (y_pred) to compute the model's loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2787483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_MSE\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "    \n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "        reg = reg = tf.math.reduce_mean(tf.square(0.5 - y_pred), axis=-1)\n",
    "        return mse + reg * self.regularization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5176f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input((10)),\n",
    "    layers.Dense(10, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=CustomMSE(regularization_factor=0.2), optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6102a154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.2909\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2894\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2879\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2864\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2849\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2834\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2819\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2805\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2790\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63caf7b940>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_true, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b1330",
   "metadata": {},
   "source": [
    "## 3. Loss Function Wrapper bases custom loss\n",
    "- Alternatively you could implement the loss function as a method, and use the **LossFunctionWrapper** to turn it into a class.\n",
    "- This wrapper is a subclass of **tf.keras.losses.Loss** which handles the parsing of extra arguments by passing them to the **call()** and **config methods**.\n",
    "\n",
    "\n",
    "The LossFunctionWrapper's __init__() method takes the following arguments:\n",
    "- **fn**: The loss function to wrap, with signature fn(y_true, y_pred, **kwargs).\n",
    "- **reduction**: Type of tf.keras.losses.Reduction to apply to loss.\n",
    "- **name**: Optional name for the instance.\n",
    "- Any other parameters will be passed to fn as kwargs through the call() method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb91d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow keras doesnot have LossFunctionWrapper\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0db381d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input((10)),\n",
    "    layers.Dense(10, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c7c3dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(y_true, y_pred, regularization_factor=0.1):\n",
    "    mse = tf.math.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "    reg = tf.math.reduce_mean(tf.square(0.5 - y_pred), axis=-1)\n",
    "    return mse + reg * regularization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eddb9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedCustomMSE(losses.LossFunctionWrapper):\n",
    "    def __init__(self, \n",
    "        reduction=tf.keras.losses.Reduction.AUTO,\n",
    "        name=\"custom_mse_with_regularization\",\n",
    "        regularization_factor=0.1,\n",
    "    ):\n",
    "        \n",
    "        super().__init__(fn=custom_MSE,\n",
    "                        reduction=reduction,\n",
    "                        name=name,\n",
    "                        regularization_factor=regularization_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ac401949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=WrappedCustomMSE(regularization_factor=0.2, name=\"mse_custom_0_2\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ec1520f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 0.2725\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2708\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2692\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2675\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2659\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2643\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2626\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2611\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2596\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63c9e8a350>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_true, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e20c7f",
   "metadata": {},
   "source": [
    "## 4. Nasted function (not mentioned in the official documentation)\n",
    "- Use subclassing approach insted of this as it is not mentioned in the official documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ba3c7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_MSE(regularization_factor):\n",
    "    def MSE(y_pred, y_true):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred), axis=-1)\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred), axis=-1)\n",
    "        return mse + reg * regularization_factor\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e605d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input((10)),\n",
    "    layers.Dense(10, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=custom_MSE(regularization_factor=0.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "31529566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.3893\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3869\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3846\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3823\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3800\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3778\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3756\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3734\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3712\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f63e8d03b50>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_true, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b28e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
