{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23795f94",
   "metadata": {},
   "source": [
    "# Custom Metrics\n",
    "\n",
    "In machine learning, metrics are evaluation measures used to assess the performance and effectiveness of a model. They provide quantitative information about how well the model is performing on a specific task, such as classification, regression, or clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb84f5",
   "metadata": {},
   "source": [
    "**Loss**:\n",
    "- Loss is a value that quantifies the error or discrepancy between the predicted output of a model and the true expected output during training.\n",
    "- The loss function is defined based on the specific task and data, and its purpose is to guide the model's optimization process by minimizing the error.\n",
    "- During training, the model learns by adjusting its parameters to minimize the loss.\n",
    "\n",
    "**Metrics**:\n",
    "- Metrics are evaluation measures that assess the performance and effectiveness of a model on a specific task.\n",
    "- Metrics provide insights into various aspects of the model's performance, such as accuracy, precision, recall, F1 score, mean squared error, etc.\n",
    "- While the loss function guides the model's optimization, metrics provide a more comprehensive view of the model's performance from a user's perspective.\n",
    "\n",
    "In summary, loss is an optimization criterion used during training to adjust the model's parameters, while metrics are evaluation measures used to assess the model's performance on unseen data or in real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12021e",
   "metadata": {},
   "source": [
    "### By Subclassing\n",
    "- If you need a metric that isn't part of the API, you can easily create custom metrics by subclassing the **tf.keras.metrics.Metric** class.\n",
    "- You will need to implement 4 methods:\n",
    "   - **\\_\\_init\\_\\_**(self), in which you will create state variables for your metric.\n",
    "   - **update_state(self, y_true, y_pred, sample_weight=None)**, which uses the targets y_true and the model predictions y_pred to update the state variables.\n",
    "   - **result(self)**, which uses the state variables to compute the final results.\n",
    "   - **reset_state(self)**, which reinitializes the state of the metric.\n",
    "\n",
    "- **State update** and **results computation** are kept separate (in update_state() and result(), respectively) because in some cases, the results computation might be very expensive and would only be done periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15a04e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e71379",
   "metadata": {},
   "source": [
    "Here's a simple example showing how to implement a CategoricalTruePositives metric that counts how many samples were correctly classified as belonging to a given class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e143305",
   "metadata": {},
   "source": [
    "**Note**: In the custom metric example provided, the use of **add_weight** is not mandatory, but it is a recommended approach to define and track the metric's internal variables. By using add_weight, the internal variables are automatically *tracked* by Keras and can be *accessed*, *initialized*, and *updated* within the metric class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "975fcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positive\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positive = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.math.equal(tf.cast(y_true, \"int32\"), tf.cast(y_pred, \"int32\"))\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positive.assign_add(tf.reduce_sum(values))\n",
    "    def result(self):\n",
    "        return self.true_positive\n",
    "    def reset_state(self):\n",
    "        self.true_positive.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "184661ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 44        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154\n",
      "Trainable params: 154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input((10)),\n",
    "    layers.Dense(10, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f88d6fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([10, 10]),\n",
       " TensorShape([10, 1]),\n",
       " <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[1.],\n",
       "        [3.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [2.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([10, 10])\n",
    "y_true = tf.math.round(tf.random.uniform((10, 1), minval=0, maxval=3))\n",
    "x.shape, y_true.shape, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2c762806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[CategoricalTruePositives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "34141463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 1.7789 - categorical_true_positive: 2.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7640 - categorical_true_positive: 3.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7491 - categorical_true_positive: 3.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7343 - categorical_true_positive: 3.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7196 - categorical_true_positive: 3.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7051 - categorical_true_positive: 3.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6906 - categorical_true_positive: 3.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6763 - categorical_true_positive: 3.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6621 - categorical_true_positive: 3.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6480 - categorical_true_positive: 3.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47c81b50c0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y_true, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f586984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f9d078f",
   "metadata": {},
   "source": [
    "# Handling losses and metrics that doesnot fit the standard signature\n",
    "[more](https://www.tensorflow.org/guide/keras/training_with_built_in_methods#handling_losses_and_metrics_that_dont_fit_the_standard_signature)\n",
    "\n",
    "- The overwhelming majority of losses and metrics can be computed from y_true and y_pred, where y_pred is an output of your model -- but not all of them. For instance, a regularization loss may only require the activation of a layer (there are no targets in this case), and this activation may not be a model output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45e36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
