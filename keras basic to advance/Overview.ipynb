{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef01c062",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "- Keras is the high-level API of the TensorFlow platform. It provides an approachable, highly-productive interface for solving machine learning (ML) problems, with a focus on modern deep learning. Keras covers every step of the machine learning workflow, from data processing to hyperparameter tuning to deployment. It was developed with a focus on enabling fast experimentation.\n",
    "\n",
    "- Keras is designed to reduce cognitive load by achieving the following goals:\n",
    "    - Offer simple, consistent interfaces.\n",
    "    - Minimize the number of actions required for common use cases.\n",
    "    - Provide clear, actionable error messages.\n",
    "    -Follow the principle of progressive disclosure of complexity: It's easy to get started, and you can complete advanced workflows by learning as you go.\n",
    "    - Help you write concise, readable code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbdcc7",
   "metadata": {},
   "source": [
    "# Keras API components\n",
    "The core data structures of Keras are layers and models.\n",
    "- **layers**: \n",
    "    - A layer is a simple input/output transformation \n",
    "    - The tf.keras.layers.Layer class is the fundamental abstraction in Keras. A Layer encapsulates a state (weights) and some computation (defined in the tf.keras.layers.Layer.call method).\n",
    "    - You can also use layers to handle data preprocessing tasks like normalization and text vectorization.\n",
    "    - Preprocessing layers can be included directly into a model, either during or after training, which makes the model portable.\n",
    "    \n",
    "- **models**: \n",
    "    - A model is a directed acyclic graph (DAG) of layers.\n",
    "    - A model is an object that groups layers together and that can be trained on data.\n",
    "\n",
    "The tf.keras.Model class features built-in training and evaluation methods:\n",
    "   - **tf.keras.Model.fit**: Trains the model for a fixed number of epochs.\n",
    "   - **tf.keras.Model.predict**: Generates output predictions for the input samples.\n",
    "   - **tf.keras.Model.evaluate**: Returns the loss and metrics values for the model; configured via the tf.keras.Model.compile method.\n",
    "   \n",
    "These methods give you access to the following built-in training features:\n",
    "   - **Callbacks**: You can leverage built-in callbacks for early stopping, model checkpointing, and TensorBoard monitoring. You can also implement custom callbacks.\n",
    "   - **Distributed training**: You can easily scale up your training to multiple GPUs, TPUs, or devices.\n",
    "   - **Step fusing**: With the steps_per_execution argument in tf.keras.Model.compile, you can process multiple batches in a single tf.function call, which greatly improves device utilization on TPUs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce18a34",
   "metadata": {},
   "source": [
    "# Building simple model with keras.layers.Layer\n",
    "\n",
    "- **tf.keras.layers.Layer** is the base class of all Keras layers, and it inherits from **tf.Module**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8a7c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 07:18:57.795969: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-16 07:18:57.993237: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-16 07:18:57.994207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-16 07:18:59.055312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1764f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, in_features, out_features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.w = tf.Variable(tf.random.normal([in_features, out_features]), name=\"w\")\n",
    "        self.b = tf.Variable(tf.zeros([out_features]), name=\"b\")\n",
    "    \n",
    "    def call(self, x): # note that instead of using __call__ like in tf.Module, we are just using call() method\n",
    "        z = x @ self.w + self.b\n",
    "        return tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3035e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-0.6004024 , -0.97726893],\n",
       "        [-0.7292261 ,  0.8978605 ],\n",
       "        [-0.39256954,  0.7489062 ]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_layer = MyDense(3, 2)\n",
    "simple_layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42414a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.       , 1.418404 ],\n",
       "       [0.       , 0.5900894]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_layer([[1.0 , 1.0, 2.0],\n",
    "              [2.0, 2.0, 1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306316e7",
   "metadata": {},
   "source": [
    "### with build step\n",
    "- As noted, it's convenient in many cases to wait to create variables until you are sure of the input shape.\n",
    "- build is called exactly once, and it is called with the shape of the input. It's usually used to create variables (weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "28921052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleDense(tf.keras.layers.Layer):\n",
    "    def __init__(self, out_features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.out_features = out_features\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = tf.Variable(tf.random.normal([input_shape[-1], self.out_features]), name=\"w\")\n",
    "        self.b = tf.Variable(tf.zeros([self.out_features]), name=\"b\")\n",
    "    \n",
    "    def call(self, x):\n",
    "        y = x @ self.w + self.b\n",
    "        return tf.nn.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "669fad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "flexible_dense = FlexibleDense(out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c9a63816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexible_dense.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecacd84",
   "metadata": {},
   "source": [
    "Weights are not initialized yet, It won't be aviable not until the \"call\" method will be called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "72a755ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[1.0, 2.0, 3.0]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "144b205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.       , 1.1477716]], dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexible_dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "db9e1677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'flexible_dense_43/w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-1.9676659 ,  0.64514977],\n",
       "        [-0.37998724,  0.41509008],\n",
       "        [ 0.29196718, -0.10918608]], dtype=float32)>,\n",
       " <tf.Variable 'flexible_dense_43/b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flexible_dense.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3fa80",
   "metadata": {},
   "source": [
    "As we can see, weights are initialized now. [source code](https://github.com/keras-team/keras/blob/e327db2f7016e3605593f6687e48daf815391a7f/keras/engine/base_layer.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdacc63",
   "metadata": {},
   "source": [
    "## Keras model\n",
    "- We can define model as a nested keras layers (using base class **keras.layers.Layers**), like we used tf.Module to define model as well as it's layers.\n",
    "- However, Keras also provides a full-featured model class called **tf.keras.Model**. It inherits from **tf.keras.layers.Layer**, so a Keras model can be used and nested in the same way as Keras layers. \n",
    "\n",
    "- class inheritances:\n",
    "    - **tf.Module --> keras.layers.Layers ---> keras.Model**\n",
    "    - notation: base-class --> derived_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "260fa02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequentialModel(tf.keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dense1 = FlexibleDense(out_features=4)\n",
    "        self.dense2 = FlexibleDense(out_features=2)\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e2be6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySequentialModel(name=\"simplest model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "10f72c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.\n"
     ]
    }
   ],
   "source": [
    "# singel weights are not yet initialized, it will throw an exception\n",
    "try:\n",
    "    model.summary()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(tf.constant([[1., 2., 3.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc3ddbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.FlexibleDense at 0x7fa738187c40>,\n",
       " <__main__.FlexibleDense at 0x7fa7307a0cd0>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.submodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1cfe52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"simplest model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flexible_dense_44 (Flexible  multiple                 16        \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " flexible_dense_45 (Flexible  multiple                 10        \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26\n",
      "Trainable params: 26\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2eed1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
