{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db3191f1",
   "metadata": {},
   "source": [
    "# Modules, layers and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4267c9d",
   "metadata": {},
   "source": [
    "## Models\n",
    "A model is, abstractly:\n",
    "- A function that computes something on tensors (a forward pass)\n",
    "- Some variables that can be updated in response to training\n",
    "\n",
    "## Modules\n",
    "- Most models are made of layers. \n",
    "- Layers are functions with a known mathematical structure that can be reused and have trainable variables. \n",
    "- In TensorFlow, most high-level implementations of layers and models, such as Keras or Sonnet, are built on the same foundational class: **tf.Module**.\n",
    "- Modules in TensorFlow provide a means to encapsulate related functionality, such as layers, blocks, or custom operations, into a reusable unit.\n",
    "\n",
    "In summary,\n",
    "- \"**models**\" in TensorFlow refer to higher-level abstractions that encompass the architecture and functionality of machine learning models, often defined by subclassing **tf.keras.Model**.\n",
    "- \"**Modules**\", on the other hand, refer to reusable blocks or components that can be used within models, often defined by subclassing **tf.Module**. Modules help with code organization, modularity, and reusability, allowing you to encapsulate related functionality into separate units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dff4a7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 21:01:34.434771: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-13 21:01:34.482282: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-13 21:01:34.484097: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 21:01:35.422435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd2b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModule(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        # You can set the trainability of variables on and off for any reason, \n",
    "        # including freezing layers and variables during fine-tuning.\n",
    "        self.a_variable = tf.Variable(5.0, trainable=True, name=\"train\")\n",
    "        self.non_trainable_var = tf.Variable(5.0, trainable=False, name=\"non trainable\")\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        return self.a_variable * inputs + self.non_trainable_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b31f5e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simple'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_module = SimpleModule(\"simple\")\n",
    "simple_module.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd6e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=15.0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_module(tf.Variable(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7f3f9",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "- ***tf.Module*** is the base class for both **tf.keras.layers.Layer** and **tf.keras.Model**, so everything you come across here also applies in Keras.\n",
    "-  For historical compatibility reasons Keras layers do not collect variables from modules, so your models should use only modules or only Keras layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4b4f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'train:0' shape=() dtype=float32, numpy=5.0>,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the trainable variables\n",
    "simple_module.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4338d8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'train:0' shape=() dtype=float32, numpy=5.0>,\n",
       " <tf.Variable 'non trainable:0' shape=() dtype=float32, numpy=5.0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of all the variables assigned to the simple_module\n",
    "simple_module.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f4903",
   "metadata": {},
   "source": [
    "### Building two layer model using Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c810aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "    def __init__(self,in_features, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.weights = tf.Variable(tf.random.normal([in_features, out_features], name=\"W\"))\n",
    "        self.bias = tf.Variable(tf.zeros(out_features), name=\"b\")\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        z = inputs @ self.weights + self.bias\n",
    "        return tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8392038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.dense1 = Dense(in_features=4, out_features=3, name=\"dense1\")\n",
    "        self.dense2 = Dense(in_features=3, out_features=2, name=\"dense2\")\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        out1 = self.dense1(inputs)\n",
    "        out2 = self.dense2(out1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f19cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model\n",
    "model = SequentialModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbfea328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:  tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1., 1., 0., 1.]])\n",
    "\n",
    "print(\"Model output: \", model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b72d969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(4, 3) dtype=float32, numpy=\n",
       " array([[ 0.27624676,  0.8140204 , -1.423646  ],\n",
       "        [-0.01590264, -1.0349654 , -0.7415145 ],\n",
       "        [ 0.6664191 , -0.3525899 , -0.816536  ],\n",
       "        [ 0.07416085, -0.1692806 , -0.16368097]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-1.1496557 , -1.6198384 ],\n",
       "        [ 0.13141622,  0.80947703],\n",
       "        [-0.63101864,  0.09868614]], dtype=float32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd242ed",
   "metadata": {},
   "source": [
    "tf.Module instances will automatically collect, recursively, any tf.Variable or tf.Module instances assigned to it. This allows you to manage collections of tf.Modules with a single model instance, and save and load whole models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce02270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all the submodules:  (<__main__.Dense object at 0x7fa3d7195360>, <__main__.Dense object at 0x7fa3d7197730>)\n",
      "List of the name of the submodules:  ['dense1', 'dense2']\n"
     ]
    }
   ],
   "source": [
    "print(\"List of all the submodules: \", model.submodules)\n",
    "print(\"List of the name of the submodules: \", [sub.name for sub in model.submodules])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa73495",
   "metadata": {},
   "source": [
    "### Waiting to create variable \n",
    "- No need to specify both input and output shape to the layer\n",
    "- flexible size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd21560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleDense(tf.Module):\n",
    "    def __init__(self, out_features, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.is_built = False\n",
    "        self.out_features = out_features\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        if not self.is_built:\n",
    "            self.weights = tf.Variable(\n",
    "                tf.random.normal([x.shape[-1], self.out_features]),\n",
    "                name=\"w\"\n",
    "            )\n",
    "            self.bias = tf.Variable(tf.zeros(self.out_features), name=\"b\")\n",
    "            self.is_built = True\n",
    "        z = x @ self.weights + self.bias\n",
    "        return tf.nn.relu(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "801f2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.dense1 = FlexibleDense(out_features=3, name=\"dense1\")\n",
    "        self.dense2 = FlexibleDense(out_features=2, name=\"dense2\")\n",
    "    \n",
    "    def __call__(self, inputs):\n",
    "        out1 = self.dense1(inputs)\n",
    "        out2 = self.dense2(out1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e961c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model results (input_shape = 3): tf.Tensor([[0. 0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "my_model = SequentialModel(name=\"flexible_model\")\n",
    "print(\"Model results (input_shape = 3):\", my_model(tf.constant([[2.0, 2.0, 1.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77b3dbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0.]\n",
      "  [0. 0.]]], shape=(1, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44385d51",
   "metadata": {},
   "source": [
    "## saving weights\n",
    "- You can save a **tf.Module** as both a **checkpoint** and a **SavedModel**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577f4ce",
   "metadata": {},
   "source": [
    "#### Checkpoint\n",
    "- Checkpoints are just the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec3e756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_checkpoint'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chkp_path = \"my_checkpoint\"\n",
    "checkpoint = tf.train.Checkpoint(model=my_model)\n",
    "checkpoint.write(chkp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f75ae1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'b:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[-1.6191789, -1.2352841,  0.1626661],\n",
       "        [ 0.7143987, -0.2580629, -1.160111 ],\n",
       "        [ 0.9796424,  1.2809355,  0.6541501]], dtype=float32)>,\n",
       " <tf.Variable 'b:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'w:0' shape=(3, 2) dtype=float32, numpy=\n",
       " array([[-1.4439256 , -0.00888472],\n",
       "        [-1.0444151 ,  1.3851212 ],\n",
       "        [-1.2846667 , -0.0374243 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.model.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dddf997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_CHECKPOINTABLE_OBJECT_GRAPH', []),\n",
       " ('model/dense1/bias/.ATTRIBUTES/VARIABLE_VALUE', [3]),\n",
       " ('model/dense1/weights/.ATTRIBUTES/VARIABLE_VALUE', [3, 3]),\n",
       " ('model/dense2/bias/.ATTRIBUTES/VARIABLE_VALUE', [2]),\n",
       " ('model/dense2/weights/.ATTRIBUTES/VARIABLE_VALUE', [3, 2])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can look inside a checkpoint to be sure the whole collection of variables is saved,\n",
    "# sorted by the Python object that contains them\n",
    "tf.train.list_variables(chkp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22586214",
   "metadata": {},
   "source": [
    "During distributed (multi-machine) training they can be sharded, which is why they are numbered (e.g., '00000-of-00001'). In this case, though, there is only one shard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58575f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = SequentialModel()\n",
    "new_checkpoint = tf.train.Checkpoint(model=new_model)\n",
    "new_checkpoint.restore(\"my_checkpoint\")\n",
    "\n",
    "# Should be the same result as above\n",
    "new_model(tf.constant([[2.0, 2.0, 2.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266ff40",
   "metadata": {},
   "source": [
    "## Saving functions\n",
    "- TensorFlow can run models without the original Python objects.\n",
    "- TensorFlow needs to know how to do the computations described in Python, but without the original code. To do this, you can make a graph.\n",
    "- You can define a graph in the model above by adding the **@tf.function** decorator to indicate that this code should run as a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735012b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialModel(tf.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.dense1 = FlexibleDense(out_features=3, name=\"dense1\")\n",
    "        self.dense2 = FlexibleDense(out_features=2, name=\"dense2\")\n",
    "    \n",
    "    @tf.function\n",
    "    def __call__(self, inputs):\n",
    "        out1 = self.dense1(inputs)\n",
    "        out2 = self.dense2(out1)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f53d3a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Model results (input_shape = 3): tf.Tensor([[0.        1.7730099]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "my_model = SequentialModel(name=\"flexible_model\")\n",
    "print(isinstance(my_model, SequentialModel))\n",
    "print(\"Model results (input_shape = 3):\", my_model(tf.constant([[2.0, 2.0, 1.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29702fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(my_model([[[2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43bb88",
   "metadata": {},
   "source": [
    "The module you have made works exactly the same as before. Each unique signature passed into the function creates a separate graph. Check the Introduction to graphs and functions guide for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a077fd",
   "metadata": {},
   "source": [
    "#### You can visualize the graph by tracing it within a TensorBoard summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f963239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up logging.\n",
    "# stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# logdir = \"logs/func/%s\" % stamp\n",
    "# writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# # Create a new model to get a fresh trace\n",
    "# # Otherwise the summary will not see the graph.\n",
    "# new_model = SequentialModel()\n",
    "\n",
    "# # Bracket the function call with\n",
    "# # tf.summary.trace_on() and tf.summary.trace_export().\n",
    "# tf.summary.trace_on(graph=True)\n",
    "# tf.profiler.experimental.start(logdir)\n",
    "# # Call only one tf.function when tracing.\n",
    "# z = print(new_model(tf.constant([[2.0, 2.0, 2.0]])))\n",
    "# with writer.as_default():\n",
    "#     tf.summary.trace_export(\n",
    "#       name=\"my_func_trace\",\n",
    "#       step=0,\n",
    "#       profiler_outdir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b23b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_infra: no_execute\n",
    "# %tensorboard --logdir logs/func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3f4a1",
   "metadata": {},
   "source": [
    "### Saving model\n",
    "-  SavedModel contains both a collection of functions and a collection of weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04440ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: the_saved_model_2/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(my_model, \"the_saved_model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e1e1a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Gradient and Automatic Differentiation.ipynb'\t'Tensorflow Components.ipynb'\r\n",
      " Modules_layers_models.ipynb\t\t\t'Tensorflow operations.ipynb'\r\n",
      " my_checkpoint.data-00000-of-00001\t\t the_saved_model_2\r\n",
      " my_checkpoint.index\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19ca8b",
   "metadata": {},
   "source": [
    "### Loading the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a004d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7fa3cc255ea0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = tf.saved_model.load(\"the_saved_model_2\")\n",
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14a79867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(new_model, SequentialModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e50523",
   "metadata": {},
   "source": [
    "new_model, created from loading a saved model, is an internal TensorFlow user object without any of the class knowledge. It is not of type SequentialModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f44a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(my_model, SequentialModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b441c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 0.       27.373873]], shape=(1, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.       18.471558]\n",
      "  [ 0.       14.634044]\n",
      "  [ 0.        7.12486 ]]], shape=(1, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(my_model([[2, 12, 23]]))\n",
    "print(my_model([[[12.0,12.0, 12.0], [2.0, 12.0, 12.0], [3.0, 4.0, 5.0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fbee9",
   "metadata": {},
   "source": [
    "This new model works on the already-defined input signatures. You can't add more signatures to a model restored like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8638c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.        6.4120345]], shape=(1, 2), dtype=float32)\n",
      "ValueError\n"
     ]
    }
   ],
   "source": [
    "print(new_model([[20, 12, 1]]))\n",
    "try:\n",
    "    print(new_model([[[12.0,12.0, 12.0], [2.0, 12.0, 12.0], [3.0, 4.0, 5.0]]]))\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55c336a",
   "metadata": {},
   "source": [
    "**Explaination**:\n",
    "- When we run the newly created model, it will trace the graph if @tf.function has been used to decorate (new graph for new signature), if @tf.function is not used we won't be able to run the loaded model.\n",
    "- And since we haven't run the my_model with the signature (1, 3, 3), so no graph is created with that signature, upon running the loaded model, thus, we got the value error.\n",
    "- But you may notice that my_model (not a loaded model) can run without any error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee091a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
